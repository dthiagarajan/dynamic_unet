{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net\n",
    "> We expose the functionality for setting up the dynamic U-Net using our encoder and decoder packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dynamic_unet.decoder import ConcatLayer, ConvLayer, DecoderConnect, LambdaLayer, upconv2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crux of constructing the decoder happens in the `setup_decoder` function call below, and consequently in the `construct_decoder`. The details are hard to extract from the code below, so we can break it down as follows (tracing the code in the `setup_decoder` function first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Shapes Using Hooks\n",
    "\n",
    "We're going to gather the input size and output size of a tensor to any layer in the ResNet encoder network with a name that has the prefix \"layer\". To do so, we'll use hooks. Specifically, a hook is a closure, i.e. a function that's passed as an argument when registering a hook for a specific layer in our network. You can see here that\n",
    "* `shape_hook` is the function passed when registering a hook\n",
    "* We `register_forward_hook` for any `child` layer of our network that has a name that `startswith` layer, e.g. `self.layer0`, `self.layer1`, and so on.\n",
    "\n",
    "Note the specification for `shape_hook`, and generally for the function passed to `register_forward_hook` - it will have access to the input and output of the layer we are calling `register_forward_hook` for (note that input and output can be tuples here). In our case, we only care about their shapes, as we'll need the shape to determine the shape of the decoder's input, and accordingly the number of filters the convolutional layers need to output in the previous layer.\n",
    "\n",
    "Accordingly, we'll take those shapes, and add them to our `input_sizes` and `output_sizes` array, to keep track of the input and output shapes as the network processes an input. To actually populate these arrays, we have to do exctly that - process an input. Thus, we'll make a dummy input (in the code, `test_input`) that we pass through our encoder, and after it finishes processing that input, our `input_sizes` and `output_sizes` array will be populated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Decoder\n",
    "\n",
    "Now that we have the input and output sizes of any tensors passing through the blocks of our ResNet encoder, we can construct our decoder level by level. To do so, we'll just look at the following things:\n",
    "* How much we need to upsample the size of the image (determined by looking at the ratio of the input image size and the output image size)\n",
    "* What the difference in channels between the input and output of the corresponding encoder level are (determined by looking at the ratio of channels between input and output)\n",
    "\n",
    "Looking at both of these gives us a sense of the operation we need to do to reverse what the encoder did. Specifically, we can abide by the following assumptions when constructing the decoder:\n",
    "* The shape of the input to the level of the decoder we're working on will be the same as the shape of the output of the corresponding level of the encoder\n",
    "* The shape of the output of this level of the decoder will be the same shape as the shape of the input of the corresponding level of the encoder\n",
    "\n",
    "With these assumptions in mind, and using the details above for constructing the operations for each level of the decoder, we can just use case work for actually constructing the decoder, depending on whether we're looking at the last layer of the encoder, one of the middle layers, or the first layer of the encoder.\n",
    "\n",
    "Since we're starting from the inputs and outputs of the first layer of the encoder, we add on the constructed layers as we inspect the shapes of the inputs and outputs of the encoder, and then reverse the list of constructed layers when finalizing the decoder architecture, to ensure that we go from the last output shape of the encoder to the first input shape of the encoder, which is (generally) what we want to output for segmentation. (This doesn't necessarily have to be true, in which case, a 1x1 convolution is added at the end of the decoder to get the right number of output channels, specified in the constructing of the class as `num_output_channels`.\n",
    "\n",
    "Note that we maintain the decoder as a list of modules, i.e. an `nn.ModuleList`. This is an intentional choice, as we'll need to perform the operations of our network in sequence by level, as each level requires getting the corresponding output of the encoder, and processing it alongside the corresponding input of the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Forward Using Hooks\n",
    "\n",
    "The last part of setting up our dynamic U-Net architecture is to specify the `forward` function. In order to do so, we need to keep track of the outputs of each level of our encoder. Since we've encompassed the encoder as one module when constructing our U-Net, the easiest way to get the outputs for each level of the encoder is to just use hooks again.\n",
    "\n",
    "The setup for these hooks is very similar to how we set up the shape hooks above, but instead, we only keep track of the outputs, and we want the actual output tensor, not the shape. This is encompassed in the `encoder_output_hook` hook in the forward function below. Again, we register the hook for all layers in our encoder that have name starting with \"layer\".\n",
    "\n",
    "To actually use these outputs, we only need to keep track of the corresponding input we are passing into the current level of the decoder. This becomes convenient to do since we left the decoder as an `nn.ModuleList`, so we need only iterate over the encoder outputs and the corresponding layer of the decoder that they'll be passed into with the corresponding input to the decoder. This is encompassed in the following loop in the `forward` function:\n",
    "\n",
    "```\n",
    "prev_output = None\n",
    "for reo, rdl in zip(reversed(encoder_outputs), self.decoder):\n",
    "    if prev_output is not None:\n",
    "        prev_output = rdl({0: reo, 1: prev_output})\n",
    "    else:\n",
    "        prev_output = rdl(reo)\n",
    "```\n",
    "\n",
    "Note how that for the first layer of the decoder (the one that ties with the last layer of the encoder), there's no previous output. This is because the first layer of the decoder has the additional pathway (seen at the bottom of the U-Net architecture figure) that is concatenated with the output of the last layer of the encoder. On the other hand, for all other layers, the encoder output (`reo`) and the decoder input (`prev_output`) are concatenated together in a single pathway (explicitly, via the `ConcatLayer` forward function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DynamicUNet(nn.Module):\n",
    "    def __init__(self, encoder, input_size=(224, 224), num_output_channels=None, verbose=0):\n",
    "        super(DynamicUNet, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.verbose = verbose\n",
    "        self.input_size = input_size\n",
    "        self.num_input_channels = 3  # This must be 3 because we're using a ResNet encoder\n",
    "        self.num_output_channels = num_output_channels\n",
    "        \n",
    "        self.decoder = self.setup_decoder()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoder_outputs = []\n",
    "        def encoder_output_hook(self, input, output):\n",
    "            encoder_outputs.append(output)\n",
    "\n",
    "        handles = [\n",
    "            child.register_forward_hook(encoder_output_hook) for name, child in self.encoder.named_children()\n",
    "            if name.startswith('layer')\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            self.encoder(x)\n",
    "        finally:\n",
    "            if self.verbose >= 1:\n",
    "                print(\"Removing all forward handles\")\n",
    "            for handle in handles:\n",
    "                handle.remove()\n",
    "\n",
    "        prev_output = None\n",
    "        for reo, rdl in zip(reversed(encoder_outputs), self.decoder):\n",
    "            if prev_output is not None:\n",
    "                prev_output = rdl({0: reo, 1: prev_output})\n",
    "            else:\n",
    "                prev_output = rdl(reo)\n",
    "        return prev_output\n",
    "                \n",
    "    def setup_decoder(self):\n",
    "        input_sizes = []\n",
    "        output_sizes = []\n",
    "        def shape_hook(self, input, output):\n",
    "            input_sizes.append(input[0].shape)\n",
    "            output_sizes.append(output.shape)\n",
    "\n",
    "        handles = [\n",
    "            child.register_forward_hook(shape_hook) for name, child in self.encoder.named_children()\n",
    "            if name.startswith('layer')\n",
    "        ]    \n",
    "\n",
    "        self.encoder.eval()\n",
    "        test_input = torch.randn(1, self.num_input_channels, *self.input_size)\n",
    "        try:\n",
    "            self.encoder(test_input)\n",
    "        finally:\n",
    "            if self.verbose >= 1:\n",
    "                print(\"Removing all shape hook handles\")\n",
    "            for handle in handles:\n",
    "                handle.remove()\n",
    "        decoder = self.construct_decoder(input_sizes, output_sizes, num_output_channels=self.num_output_channels)\n",
    "        return decoder\n",
    "        \n",
    "    def construct_decoder(self, input_sizes, output_sizes, num_output_channels=None):\n",
    "        decoder_layers = []\n",
    "        for layer_index, (input_size, output_size) in enumerate(zip(input_sizes, output_sizes)):\n",
    "            upsampling_size_factor = int(input_size[-1] / output_size[-1])\n",
    "            upsampling_channel_factor = input_size[-3] / output_size[-3]\n",
    "            next_layer = []\n",
    "            bs, c, h, w = input_size\n",
    "            ops = []\n",
    "            if layer_index == len(input_sizes) - 1:\n",
    "                last_layer_ops = DecoderConnect(output_size[-3], output_size[2:])\n",
    "                last_layer_ops_input = torch.randn(*output_size)\n",
    "                last_layer_concat_ops_output = last_layer_ops(last_layer_ops_input)\n",
    "                next_layer.extend([last_layer_ops])\n",
    "                if upsampling_size_factor > 1 or upsampling_channel_factor != 1:\n",
    "                    last_layer_concat_upconv_op = upconv2x2(output_size[-3], input_size[-3], size=input_size[2:])\n",
    "                    last_layer_concat_upconv_op_output = nn.Sequential(*last_layer_concat_upconv_op)(\n",
    "                        last_layer_concat_ops_output\n",
    "                    )\n",
    "                    next_layer.extend(last_layer_concat_upconv_op)\n",
    "            elif layer_index == 0:\n",
    "                first_layer_concat_ops = [\n",
    "                    ConcatLayer(),\n",
    "                    ConvLayer(output_size[-3] * 2, output_size[-3] * 2, kernel_size=1),\n",
    "                    *upconv2x2(\n",
    "                        output_size[-3] * 2,\n",
    "                        output_size[-3],\n",
    "                        size=[dim * upsampling_size_factor for dim in output_size[2:]]\n",
    "                    ),\n",
    "                    ConvLayer(output_size[-3], output_size[-3], kernel_size=3),\n",
    "                    ConvLayer(\n",
    "                        output_size[-3],\n",
    "                        input_size[-3] if self.num_output_channels is None else self.num_output_channels,\n",
    "                        kernel_size=1\n",
    "                    ),\n",
    "                ]\n",
    "                first_layer_concat_ops_output = nn.Sequential(*first_layer_concat_ops)(\n",
    "                    {0: torch.randn(*output_size), 1: torch.randn(*output_size)}\n",
    "                )\n",
    "                next_layer.extend(first_layer_concat_ops)\n",
    "            else:\n",
    "                middle_layer_concat_ops = [\n",
    "                    ConcatLayer(),\n",
    "                    ConvLayer(output_size[-3] * 2, output_size[-3] * 2, kernel_size=1),\n",
    "                    ConvLayer(output_size[-3] * 2, output_size[-3], kernel_size=3),\n",
    "                    ConvLayer(output_size[-3], output_size[-3], kernel_size=3)\n",
    "                ]\n",
    "                middle_layer_concat_ops_output = nn.Sequential(*middle_layer_concat_ops)(\n",
    "                    {0: torch.randn(*output_size), 1: torch.randn(*output_size)}\n",
    "                )\n",
    "                next_layer.extend(middle_layer_concat_ops)\n",
    "                if upsampling_size_factor > 1 or upsampling_channel_factor != 1:\n",
    "                    middle_layer_concat_upconv_op = upconv2x2(output_size[-3], input_size[-3], size=input_size[2:])\n",
    "                    middle_layer_concat_upconv_op_output = nn.Sequential(*middle_layer_concat_upconv_op)(\n",
    "                        middle_layer_concat_ops_output\n",
    "                    )\n",
    "                    next_layer.extend(middle_layer_concat_upconv_op)\n",
    "            decoder_layers.append(nn.Sequential(*next_layer))\n",
    "        return nn.ModuleList(reversed(decoder_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can construct our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "from dynamic_unet.encoder import resnet34 \n",
    "\n",
    "model = DynamicUNet(resnet34(), num_output_channels=32, input_size=(360, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicUNet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): DecoderConnect(\n",
       "        (bottom_process): Sequential(\n",
       "          (0): ConvLayer(\n",
       "            (layer): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (layer): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (layer): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): Upsample(size=torch.Size([12, 15]), mode=bilinear)\n",
       "        )\n",
       "        (concat_process): Sequential(\n",
       "          (0): ConcatLayer()\n",
       "          (1): ConvLayer(\n",
       "            (layer): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): ConvLayer(\n",
       "            (layer): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): ConvLayer(\n",
       "            (layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ConvLayer(\n",
       "        (layer): Conv2d(512, 256, kernel_size=(2, 2), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Upsample(size=torch.Size([23, 30]), mode=bilinear)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConcatLayer()\n",
       "      (1): ConvLayer(\n",
       "        (layer): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (layer): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (layer): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (layer): Conv2d(256, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Upsample(size=torch.Size([45, 60]), mode=bilinear)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConcatLayer()\n",
       "      (1): ConvLayer(\n",
       "        (layer): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (layer): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (layer): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (layer): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Upsample(size=torch.Size([90, 120]), mode=bilinear)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ConcatLayer()\n",
       "      (1): ConvLayer(\n",
       "        (layer): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (layer): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): ConvLayer(\n",
       "        (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): ConvLayer(\n",
       "        (layer): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): Upsample(size=torch.Size([180, 240]), mode=bilinear)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ConcatLayer()\n",
       "      (1): ConvLayer(\n",
       "        (layer): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ConvLayer(\n",
       "        (layer): Conv2d(128, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Upsample(size=[360, 480], mode=bilinear)\n",
       "      (4): ConvLayer(\n",
       "        (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): ConvLayer(\n",
       "        (layer): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn_layer): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dynamic_unet)",
   "language": "python",
   "name": "dynamic_unet"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
