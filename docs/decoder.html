---

title: Decoder

keywords: fastai
sidebar: home_sidebar

summary: "Functions to set up the dynamic decoders for use in the dynamic U-Net architecture. In particular, we utilize PyTorch hooks here."
description: "Functions to set up the dynamic decoders for use in the dynamic U-Net architecture. In particular, we utilize PyTorch hooks here."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_decoder.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to automatically construct the Decoder using the architecture given in the encoder. To do so, we'll define some helper layers as <code>nn.Module</code>s.</p>
<ul>
<li><a href="/dynamic_unet/decoder#ConvLayer"><code>ConvLayer</code></a> is just a general form of a convolution, ReLU, and batch normalization layer in sequence, with some empirical bets practices (e.g. initializing using $\frac{1}{\sqrt{5}}$ for all the weights in the convolutional layer, as per the FastAI course).</li>
<li><a href="/dynamic_unet/decoder#ConcatLayer"><code>ConcatLayer</code></a> is just a thin wrapper on the <code>torch.cat</code> function that concatenates all inputs along the channel dimension, assuming inputs are image batches, i.e. they have shape (batch size, num channels, height, width).</li>
<li><a href="/dynamic_unet/decoder#LambdaLayer"><code>LambdaLayer</code></a> is just a thin wrapper of a generic lambda function</li>
<li><a href="/dynamic_unet/decoder#upconv2x2"><code>upconv2x2</code></a> is a utility function for setting up convolutions that upsample an image. As mentioned above, in the U-Net architecture, we first concatenate the encoder output with the corresponding decoder input, so that when we upsample an image (i.e. from $(h, w)$ in size to $(2h, 2w)$ in size), we always have 2 times the amount of information (in this case, from having two times the number of channels). Accordingly, we will always convolve using an atrous convolution (where we dilate the kernel, rather than inserting 0s in the input to the convolutional layer), followed by the actual upsampling operation (using bilinear upsampling).</li>
</ul>
<p>Note: these functions remain exposed for now, but the goal is to not need them to be exposed.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConvLayer" class="doc_header"><code>class</code> <code>ConvLayer</code><a href="https://github.com/dthiagarajan/dynamic_unet/tree/master/dynamic_unet/decoder.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConvLayer</code>(<strong><code>num_inputs</code></strong>, <strong><code>num_filters</code></strong>, <strong><code>bn</code></strong>=<em><code>True</code></em>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>transpose</code></strong>=<em><code>False</code></em>, <strong><code>dilation</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConcatLayer" class="doc_header"><code>class</code> <code>ConcatLayer</code><a href="https://github.com/dthiagarajan/dynamic_unet/tree/master/dynamic_unet/decoder.py#L34" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConcatLayer</code>() :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LambdaLayer" class="doc_header"><code>class</code> <code>LambdaLayer</code><a href="https://github.com/dthiagarajan/dynamic_unet/tree/master/dynamic_unet/decoder.py#L38" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LambdaLayer</code>(<strong><code>f</code></strong>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="upconv2x2" class="doc_header"><code>upconv2x2</code><a href="https://github.com/dthiagarajan/dynamic_unet/tree/master/dynamic_unet/decoder.py#L46" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>upconv2x2</code>(<strong><code>inplanes</code></strong>, <strong><code>outplanes</code></strong>, <strong><code>size</code></strong>=<em><code>None</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Some specifics in how the decoder is coordinated (here, the first layer means the input encoding layer of the encoder, and the last layer indicates the last layer in the encoder). These details are not super important, and are probably understandable if you inspect the U-Net architecture image more closely.</p>
<ul>
<li>The first layer's output passed along, concatenated, fed through <a href="/dynamic_unet/encoder#conv3x3"><code>conv3x3</code></a> before upsampling, then fed through a regular <a href="/dynamic_unet/encoder#conv3x3"><code>conv3x3</code></a> two times, then a <a href="/dynamic_unet/encoder#conv1x1"><code>conv1x1</code></a> to output the right number of channels for segmentation output</li>
<li>The middle layers output all are passed along, concatenated, and fed through a <a href="/dynamic_unet/encoder#conv3x3"><code>conv3x3</code></a> that first halves number of channels to upsample, then a regular <a href="/dynamic_unet/encoder#conv3x3"><code>conv3x3</code></a></li>
<li>The last layer output's takes two pathways:<ul>
<li>Going down in the figure, the output goes through: max-pool (2x2), conv3x3, conv3x3, upconv2x2. These operations are encompassed in the <a href="/dynamic_unet/decoder#DecoderConnect"><code>DecoderConnect</code></a> class.</li>
<li>Going across, assed across and concatenated to the result of above step</li>
</ul>
</li>
</ul>
<p>Again, these details don't particularly matter, unless you're implementing the architecture yourself. The important point is that upsampling always happens after a concatenation of the encoder's output with the corresponding input to the corresponding level of the decoder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DecoderConnect" class="doc_header"><code>class</code> <code>DecoderConnect</code><a href="https://github.com/dthiagarajan/dynamic_unet/tree/master/dynamic_unet/decoder.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DecoderConnect</code>(<strong><code>inplanes</code></strong>, <strong><code>output_size</code></strong>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As a quick sanity check, we can initialize this to make sure everything is in order.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecoderConnect</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DecoderConnect(
  (bottom_process): Sequential(
    (0): ConvLayer(
      (layer): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ConvLayer(
      (layer): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ConvLayer(
      (layer): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1))
      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): Upsample(size=(7, 7), mode=bilinear)
  )
  (concat_process): Sequential(
    (0): ConcatLayer()
    (1): ConvLayer(
      (layer): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ConvLayer(
      (layer): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): ConvLayer(
      (layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

