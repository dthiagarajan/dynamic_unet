{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder\n",
    "> Functions to set up the dynamic decoders for use in the dynamic U-Net architecture. In particular, we utilize PyTorch hooks here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to automatically construct the Decoder using the architecture given in the encoder. To do so, we'll define some helper layers as `nn.Module`s.\n",
    "\n",
    "* `ConvLayer` is just a general form of a convolution, ReLU, and batch normalization layer in sequence, with some empirical bets practices (e.g. initializing using $\\frac{1}{\\sqrt{5}}$ for all the weights in the convolutional layer, as per the FastAI course).\n",
    "* `ConcatLayer` is just a thin wrapper on the `torch.cat` function that concatenates all inputs along the channel dimension, assuming inputs are image batches, i.e. they have shape (batch size, num channels, height, width).\n",
    "* `LambdaLayer` is just a thin wrapper of a generic lambda function\n",
    "* `upconv2x2` is a utility function for setting up convolutions that upsample an image. As mentioned above, in the U-Net architecture, we first concatenate the encoder output with the corresponding decoder input, so that when we upsample an image (i.e. from $(h, w)$ in size to $(2h, 2w)$ in size), we always have 2 times the amount of information (in this case, from having two times the number of channels). Accordingly, we will always convolve using an atrous convolution (where we dilate the kernel, rather than inserting 0s in the input to the convolutional layer), followed by the actual upsampling operation (using bilinear upsampling).\n",
    "\n",
    "Note: these functions remain exposed for now, but the goal is to not need them to be exposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, num_inputs, num_filters, bn=True, kernel_size=3, stride=1,\n",
    "                 padding=None, transpose=False, dilation=1):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        if padding is None:\n",
    "            padding = (kernel_size-1)//2 if transpose is not None else 0\n",
    "        if transpose:\n",
    "            self.layer = nn.ConvTranspose2d(num_inputs, num_filters, kernel_size=kernel_size,\n",
    "                                            stride=stride, padding=padding, dilation=dilation)\n",
    "        else:\n",
    "            self.layer = nn.Conv2d(num_inputs, num_filters, kernel_size=kernel_size,\n",
    "                                   stride=stride, padding=padding)\n",
    "        nn.init.kaiming_uniform_(self.layer.weight, a=np.sqrt(5))\n",
    "        self.bn_layer = nn.BatchNorm2d(num_filters) if bn else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        out = F.relu(out)\n",
    "        return out if self.bn_layer is None else self.bn_layer(out)\n",
    "    \n",
    "class ConcatLayer(nn.Module):\n",
    "    def forward(self, x, dim=1):\n",
    "        return torch.cat(list(x.values()), dim=dim)\n",
    "    \n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "def upconv2x2(inplanes, outplanes, size=None, stride=1):\n",
    "    if size is not None:\n",
    "        return [\n",
    "            ConvLayer(inplanes, outplanes, kernel_size=2, dilation=2, stride=stride),\n",
    "            nn.Upsample(size=size, mode='bilinear', align_corners=True)\n",
    "        ] \n",
    "    else:\n",
    "        return [\n",
    "            ConvLayer(inplanes, outplanes, kernel_size=2, dilation=2, stride=stride),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some specifics in how the decoder is coordinated (here, the first layer means the input encoding layer of the encoder, and the last layer indicates the last layer in the encoder). These details are not super important, and are probably understandable if you inspect the U-Net architecture image more closely.\n",
    "\n",
    "* The first layer's output passed along, concatenated, fed through `conv3x3` before upsampling, then fed through a regular `conv3x3` two times, then a `conv1x1` to output the right number of channels for segmentation output\n",
    "* The middle layers output all are passed along, concatenated, and fed through a `conv3x3` that first halves number of channels to upsample, then a regular `conv3x3`\n",
    "* The last layer output's takes two pathways:\n",
    "    - Going down in the figure, the output goes through: max-pool (2x2), conv3x3, conv3x3, upconv2x2. These operations are encompassed in the `DecoderConnect` class.\n",
    "    - Going across, assed across and concatenated to the result of above step\n",
    "    \n",
    "    \n",
    "Again, these details don't particularly matter, unless you're implementing the architecture yourself. The important point is that upsampling always happens after a concatenation of the encoder's output with the corresponding input to the corresponding level of the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecoderConnect(nn.Module):\n",
    "    def __init__(self, inplanes, output_size):\n",
    "        super(DecoderConnect, self).__init__()\n",
    "        self.bottom_process = nn.Sequential(\n",
    "            ConvLayer(inplanes, inplanes * 2, kernel_size=3),\n",
    "            ConvLayer(inplanes * 2, inplanes * 2, kernel_size=3),\n",
    "            *upconv2x2(inplanes * 2, inplanes, size=output_size)\n",
    "        )\n",
    "        self.concat_process = nn.Sequential(\n",
    "            ConcatLayer(),\n",
    "            ConvLayer(inplanes * 2, inplanes * 2, kernel_size=1),\n",
    "            ConvLayer(inplanes * 2, inplanes, kernel_size=3),\n",
    "            ConvLayer(inplanes, inplanes, kernel_size=3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        decoder_input = self.bottom_process(x)\n",
    "        return self.concat_process({0: x, 1: decoder_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick sanity check, we can initialize this to make sure everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "model = DecoderConnect(512, (7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderConnect(\n",
       "  (bottom_process): Sequential(\n",
       "    (0): ConvLayer(\n",
       "      (layer): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ConvLayer(\n",
       "      (layer): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ConvLayer(\n",
       "      (layer): Conv2d(1024, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Upsample(size=(7, 7), mode=bilinear)\n",
       "  )\n",
       "  (concat_process): Sequential(\n",
       "    (0): ConcatLayer()\n",
       "    (1): ConvLayer(\n",
       "      (layer): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ConvLayer(\n",
       "      (layer): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ConvLayer(\n",
       "      (layer): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn_layer): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dynamic_unet)",
   "language": "python",
   "name": "dynamic_unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
